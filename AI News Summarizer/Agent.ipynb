{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bayzid03/LangGraph-Hub/blob/main/AI%20News%20Summarizer/Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0334b6ea",
      "metadata": {
        "id": "0334b6ea"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import TypedDict, Annotated, List, Dict\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "from Ipython.display import display, Image\n",
        "from dotenv import load_dotenv\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df1434fe",
      "metadata": {
        "id": "df1434fe"
      },
      "outputs": [],
      "source": [
        "# load environment variables\n",
        "\n",
        "load_dotenv()\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\", temperature=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Agent State and Prompts"
      ],
      "metadata": {
        "id": "mZrqza1Yoe-F"
      },
      "id": "mZrqza1Yoe-F"
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsSummarizerState(TypedDict):\n",
        "  messages: Annotated[List[HumanMessage | AIMessage], \"The messages in the conversation\"]\n",
        "  search_query: str\n",
        "  search_filter: Dict[str, str]\n",
        "  raw_news_data: List[Dict]\n",
        "  processed_articles: List[Dict]\n",
        "  summary_style: str\n",
        "  final_summary: str\n",
        "\n",
        "news_search_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a news search query optimizer. Convert the user's request into an optimized search query for finding relevant news articles. Make it concise and focused.\"),\n",
        "    (\"human\", \"User request: {user_input}\\nOptimize this into a focused news search query.\"),\n",
        "])\n",
        "\n",
        "news_filter_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a news filtering assistant. Based on the user's request, determine appropriate filters for news search. Return a JSON with 'days' (1-30), 'max_results' (5-20), and 'include_domains' (empty list if no preference).\"),\n",
        "    (\"human\", \"User request: {user_input}\\nProvide search filters as JSON.\"),\n",
        "])\n",
        "\n",
        "news_summarize_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an expert news summarizer. Create a comprehensive summary of the provided news articles in {summary_style} style.\n",
        "\n",
        "Summary styles:\n",
        "- brief: 2-3 sentences per article, focus on key points\n",
        "- detailed: Full paragraph per article with context and implications\n",
        "- bullet: Key points in bullet format\n",
        "- executive: Business-focused summary with impact analysis\n",
        "\n",
        "Structure your response as:\n",
        "**NEWS SUMMARY - {search_query}**\n",
        "**Generated on: {timestamp}**\n",
        "\n",
        "**KEY HIGHLIGHTS:**\n",
        "[Overall themes and important developments]\n",
        "\n",
        "**ARTICLE SUMMARIES:**\n",
        "[Individual article summaries based on style]\n",
        "\n",
        "**SOURCES:**\n",
        "[List of sources with publication dates]\"\"\"),\n",
        "    (\"human\", \"Summarize these news articles:\\n\\n{articles_text}\"),\n",
        "])\n"
      ],
      "metadata": {
        "id": "352We-5hom7u"
      },
      "id": "352We-5hom7u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Agent Functions (Nodes)"
      ],
      "metadata": {
        "id": "eWLHxAQ50UNE"
      },
      "id": "eWLHxAQ50UNE"
    },
    {
      "cell_type": "code",
      "source": [
        "def input_search_query(state: NewsSummarizerState) -> NewsSummarizerState:\n",
        "    \"\"\"\n",
        "    Node 1: Get search query from user and optimize it using LLM\n",
        "    \"\"\"\n",
        "    print(\"üì∞ Welcome to AI News Summarizer!\")\n",
        "    print(\"Please enter your news topic or search query:\")\n",
        "    print(\"Examples: 'AI developments', 'climate change policy', 'tech earnings', 'global economy'\")\n",
        "    user_message = input(\"Enter your search query:\")\n",
        "\n",
        "    response = llm.invoke(news_search_prompt.format_messages(user_input=user_message))\n",
        "    query = response.content.strip()\n",
        "\n",
        "    return{\n",
        "        **state,\n",
        "        \"search_query\": query,\n",
        "        \"messages\": state[\"messages\"] + [HumanMessage(content=user_message)]\n",
        "    }\n",
        "\n",
        "def input_search_filters(state: NewsSummarizerState) -> NewsSummarizerState:\n",
        "    \"\"\"\n",
        "    Node 2: Get search filters and preferences from user\n",
        "    \"\"\"\n",
        "    print(\"Please specify your preferences:\")\n",
        "\n",
        "    # Get summary style\n",
        "    print(\"\\nSummary style options: brief, detailed, bullet, executive\")\n",
        "    style = input(\"Choose summary style (default: brief):\").strip().lower() or \"brief\"\n",
        "\n",
        "    # Get time range\n",
        "    print(\"\\nTime range options: 1 (today), 3 (last 3 days), 7 (last week), 30 (last month)\")\n",
        "    days = input(\"Days to search (default: 7):\").strip() or \"7\"\n",
        "\n",
        "    # Get number of articles\n",
        "    print(\"\\nNumber of articles: 5-20\")\n",
        "    max_results = input(\"Max articles to analyze (default: 10): \").strip() or \"10\"\n",
        "\n",
        "    filters = {\n",
        "        \"days\": int(days),\n",
        "        \"max_results\": int(max_results),\n",
        "        \"include_domains\": []\n",
        "    }\n",
        "\n",
        "    print(f\"\\nüìã Filters set: {filters}\")\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"search_filters\": filters,\n",
        "        \"summary_style\": style,\n",
        "        \"messages\": state['messages'] + [HumanMessage(content=f\"Filters: {filters}, Style: {style}\")],\n",
        "    }\n",
        "\n",
        "def fetch_news_articles(state: NewsSummarizerState) -> NewsSummarizerState:\n",
        "    print(f\"\\nüîé Searching for news articles about '{state['search_query']}'...\")\n",
        "\n",
        "    # Tavily API endpoint\n",
        "    tavily_url = \"https://api.tavily.com/search\"\n",
        "\n",
        "    # Prepare request payload\n",
        "    payload = {\n",
        "        \"api_key\": TAVILY_API_KEY,\n",
        "        \"query\": state[\"search_query\"],\n",
        "        \"search_depth\": \"advanced\",\n",
        "        \"include_answer\": False,\n",
        "        \"include_raw_content\": True,\n",
        "        \"max_results\": state[\"search_filters\"][\"max_results\"],\n",
        "        \"include_domains\": state[\"search_filters\"][\"include_domains\"],\n",
        "        \"exclude_domains\": [\"youtube.com\", \"twitter.com\", \"facebook.com\"],\n",
        "        \"days\": state[\"search_filters\"][\"days\"],\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Send POST request to Tavily\n",
        "        response = requests.post(\n",
        "            tavily_url,\n",
        "            json=payload,\n",
        "            headers={\"Content-Type\": \"application/json\"}\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        search_results = response.json()\n",
        "\n",
        "        # Extract articles from response\n",
        "        articles = search_results.get(\"results\", [])\n",
        "        print(f\"‚úÖ Found {len(articles)} articles\")\n",
        "\n",
        "        # Process and reformat articles\n",
        "        processed_articles = []\n",
        "        for article in articles:\n",
        "            processed_article = {\n",
        "                \"title\": article.get(\"title\", \"No Title\"),\n",
        "                \"url\": article.get(\"url\", \"\"),\n",
        "                \"content\": article.get(\"content\", \"\"),\n",
        "                \"raw_content\": article.get(\"raw_content\", \"\"),\n",
        "                \"published_date\": article.get(\"published_date\", \"Unknown\"),\n",
        "                \"score\": article.get(\"score\", 0)\n",
        "            }\n",
        "            processed_articles.append(processed_article)\n",
        "            print(f\"üìÑ {processed_article['title'][:60]}...\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "        return {\n",
        "            **state,\n",
        "            \"raw_news_data\": articles,\n",
        "            \"processed_articles\": processed_articles,\n",
        "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Found {len(articles)} articles\")],\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error fetching news: {str(e)}\")\n",
        "\n",
        "        # Fallback sample article\n",
        "        mock_articles = [{\n",
        "            \"title\": f\"Sample article about {state['search_query']}\",\n",
        "            \"content\": f\"This is sample content related to {state['search_query']} for demonstration purposes.\",\n",
        "            \"url\": \"https://example.com\",\n",
        "            \"published_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "            \"score\": 0.8\n",
        "        }]\n",
        "\n",
        "        return {\n",
        "            **state,\n",
        "            \"raw_news_data\": mock_articles,\n",
        "            \"processed_articles\": mock_articles,\n",
        "            \"messages\": state[\"messages\"] + [AIMessage(content=\"Using sample data due to API error\")],\n",
        "        }\n",
        "\n",
        "def summarize_news(state: NewsSummarizerState) -> NewsSummarizerState:\n",
        "    \"\"\"\n",
        "    Node 4: Generate AI-powered summary of fetched news articles\n",
        "    \"\"\"\n",
        "    print(f\"üìù Creating {state['summary_style']} summary of news articles...\")\n",
        "    print(f\"Processing {len(state['processed_articles'])} articles...\\n\")\n",
        "\n",
        "    # Prepare articles text for summarization\n",
        "    articles_text = \"\"\n",
        "    for i, article in enumerate(state['processed_articles'], 1):\n",
        "        content = article.get('raw_content', article.get('content', ''))\n",
        "        articles_text += f\"Article {i}:\\n\"\n",
        "        articles_text += f\"Title: {article['title']}\\n\"\n",
        "        articles_text += f\"URL: {article['url']}\\n\"\n",
        "        articles_text += f\"Published: {article.get('published_date', 'Unknown')}\\n\"\n",
        "        articles_text += f\"Content: {content[:1000]}...\\n\\n\"  # Limit content length\n",
        "\n",
        "    # Generate summary using LLM\n",
        "    response = llm.invoke(news_summarize_prompt.format_messages(\n",
        "        summary_style=state['summary_style'],\n",
        "        search_query=state['search_query'],\n",
        "        timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        articles_text=articles_text\n",
        "    ))\n",
        "\n",
        "    summary = response.content\n",
        "\n",
        "    print(\"üìä Your AI-Generated News Summary:\")\n",
        "    print(\"=\"*60)\n",
        "    print(summary)\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"final_summary\": summary,\n",
        "        \"messages\": state['messages'] + [AIMessage(content=summary)],\n",
        "    }"
      ],
      "metadata": {
        "id": "5yJCfzCL0dSu"
      },
      "id": "5yJCfzCL0dSu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRAPH CREATION AND COMPILATION"
      ],
      "metadata": {
        "id": "trgiVf1j_tPj"
      },
      "id": "trgiVf1j_tPj"
    },
    {
      "cell_type": "code",
      "source": [
        "  workflow = StateGraph(NewsSummarizerState)\n",
        "\n",
        "  workflow.add_node(\"input_search_query\", input_search_query)\n",
        "  workflow.add_node(\"input_search_filters\", input_search_filters)\n",
        "  workflow.add_node(\"fetch_news_articles\", fetch_news_articles)\n",
        "  workflow.add_node(\"summarize_news\", summarize_news)\n",
        "\n",
        "  workflow.set_entry_point(\"input_search_query\")\n",
        "\n",
        "  workflow.add_edge(\"input_search_query\", \"input_search_filters\")\n",
        "  workflow.add_edge(\"input_search_filters\", \"fetch_news_articles\")\n",
        "  workflow.add_edge(\"fetch_news_articles\", \"summarize_news\")\n",
        "  workflow.add_edge(\"summarize_news\",END)\n",
        "\n",
        "  app = workflow.compile()"
      ],
      "metadata": {
        "id": "EyGXr5Zf_ujg"
      },
      "id": "EyGXr5Zf_ujg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)))"
      ],
      "metadata": {
        "id": "xAxWEJ7DFk5X"
      },
      "id": "xAxWEJ7DFk5X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function that runs the graph\n",
        "def run_news_summarizer(user_request: str):\n",
        "    print(\"=\" * 50)\n",
        "    print(\"ü§ñ AI News Summarizer Starting...\")\n",
        "    print(f\"Initial Request: {user_request}\\n\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    state = {\n",
        "        \"messages\": [HumanMessage(content=user_request)],\n",
        "        \"search_query\": \"\",\n",
        "        \"search_filters\": {},\n",
        "        \"raw_news_data\": [],\n",
        "        \"processed_articles\": [],\n",
        "        \"summary_style\": \"brief\",\n",
        "        \"final_summary\": \"\",\n",
        "    }\n",
        "\n",
        "    for output in app.stream(state):\n",
        "        pass  # The nodes themselves handle all printing\n",
        "\n",
        "    print(\"\\nüéâ News summarization completed! Stay informed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_request = \"I want to get a summary of the latest news.\"\n",
        "    run_news_summarizer(user_request)"
      ],
      "metadata": {
        "id": "b2lkvnovIQvA"
      },
      "id": "b2lkvnovIQvA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}